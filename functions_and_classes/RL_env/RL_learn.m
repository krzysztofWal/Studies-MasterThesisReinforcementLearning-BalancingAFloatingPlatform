function [agentObj, trainingStats, info_, rng_state] = RL_learn(agentObj,env,info_,if_test_with_openAI, if_RL_repeat_env_comb, train_if_verbose)
    if_RL_repeat_env = if_RL_repeat_env_comb(1);
    if_RL_repeat_env_matlab = if_RL_repeat_env_comb(2);

    tic
    trainOpts = rlTrainingOptions(...
    'MaxEpisodes',info_.train_max_episodes, ...
    'MaxStepsPerEpisode', info_.train_max_steps_per_episode, ...
    'Verbose', train_if_verbose, ...
     'Plots','none', ...
    'StopTrainingCriteria', info_.train_stop_criteria, ...
    'StopTrainingValue',info_.train_stop_training_value, ...
    'SaveAgentCriteria',info_.train_save_criteria,...
    'SaveAgentValue',info_.train_save_value,...
    'SaveAgentDirectory', info_.train_save_path, ...
    'ScoreAveragingWindowLength',info_.train_averaging_window,...
    'UseParallel', info_.train_if_parallel);

    if ~if_test_with_openAI && ~if_RL_repeat_env_matlab
        env.ResetFcn = @(in)local_reset_fcn(in);
    end
    trainingStats = train(agentObj,env,trainOpts);
    toc

    rng_state = rng;
end

